---
title: "From Eyes to Ears: The Visual and Auditory Dynamics of Spanish Vowels for English Students"
subtitle: 
author: ""
institute: "Rutgers University"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: ["rutgers-fonts", "rutgers"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
editor_options: 
  chunk_output_type: console
---

```{r ,echo=FALSE, include=FALSE}
library(here)
library(knitr)
library(kableExtra)

```

# How do we perceive language?

.pull-left[
```{r echo=FALSE}
#| out.width: "100%"

knitr::include_graphics(here("figs", "eye1.jpg"))

```
]


.pull-right[
- Understanding involves bringing information from various sources, including the sound of speech, our knowledge of language structure, and context. 

- Visual Cues as Facilitating Agents (O’Neill, 1954; Ross et al., 2007; Sumby & Pollack, 1954).

- Current research trends: SLA bimodal speech perception indicates beneficial implications for second language acquisition (E.g., Hazan et al., 2006; Inceoglu, 2022).]

---
# Background: Speech perception. 

--

## Motor theory (Liberman & Mattingly, 1985) 
- Recognizing underlying motor commands: “tongue backing,” “lip rounding,” “jaw raising”
- McGurk effect: Fused language perception (McGurk & MacDonald, 1976) 

--

## The Direct Realist Theory (Fowler, 1986).
- Perception based on articulatory events.
- Can rely on multiple information sources

#### Effect of visual cues? How do humans perceive sound in noisy environments? 

---

# Background: Second language speech perception

--

## The Speech Learning Model (revised) (Flege & Bohn, 2021). 

- Evolving phonetic categories in second-language learning. 
- Considers the role of multiple information sources. 

--

## The Perception Assimilation Model (PAM-L2) (Best et al, 2007). 

- L2 sounds are assimilated to similar L1 sounds.
- Predictions made from phonemic inventories.
- More vowel phonemes does not equate to better perception. Escudero & Williams (2012), Gordon (2008),Inceoglu (2022). 
  
---
# Background: Second language speech and visual perception. 

## Within the PAM-L2 precepts

- Hazan et al. (2006) identified three types of visemes 
  - (1) Present in both L1 and L2 
  - (2) Unique to L2
  - (3) Different in L1 and L2 
  
A viseme was defined as: 

*Visual representation of speech through mouth & lip movements. *

- **L1 phonemes and visemes affect L2 perception**
  - L1 phonemes & visemes influence L2 perception. Hindered acquisition for Categories (2) & (3).
---

# Background: Second language speech and visual perception.  

- Fenwick et al. (2017) similar phonemes & visemes in L1 are easier to categorize. 

- Desroches et al. (2022) Bilinguals have flexible language systems. 
  - **Cross-language connections** between lexical representations and phonology.
  - Capability for top-down cross-language connections. 

- Marian et al. (2018), Bilinguals experience the McGurk effect more than monolinguals 
  - Dual visemic & phonemic inventories broaden linguistic range.
  
---

# Research Questions  

1.	Are second-language English learners of Spanish capable of identifying vowels by visually observing the respective articulation in natural speech? Does an association exist between their accuracy and language proficiency?

2.	How does the disparity between auditory and visual inputs hinder the processing of auditory information? Does a learner’s proficiency level affect their capacity to efficiently process and prioritize between two conflicting input channels?

---

# The study: Identification of Spanish vowels

.pull-left[
- **Recording** in a sound attenuated booth. 
- **Video Framing** trimmed from septal cartilage to mandible mentalis muscle.
- Target words. 
- Consonants /p, t, k, b, d, g, f, j, s and θ/. 
- With /a, e, i, o u/.
  - Created bi-syllable words.
- All possible answers were provided 
  - Audio only     50 items
  - Visual only    50 items
  - Audiovisual    50 items
  - Mismatch       50 items
- **Total**     200 items 
]
--
.pull-right[
```{r echo=FALSE}
#| out.width: "100%"
knitr::include_graphics(here("figs", "vowel_mismatch_decision.jpg"))

```
##### Procedure to create vowel mismatch condition
]
---
.pull-left[
## Procedure 
  
1. LexTALE test
2. The study
 Input was randomized 
3. Background Questionnaire

## Participants 
```{r echo=FALSE}
#| out.width: "80%"
knitr::include_graphics(here("figs", "s1part.png"))

```
]
--
.pull-right[
## Statistical analysis

- Employed Bayesian multinomial logistic regression.
- Analyzed probability of identifying one of five Spanish vowels.
- Responses modeled on condition and proficiency for: 
  - audio, 
  - visual-only 
  - audiovisual
  - audiovisual mismatch
  ]

---
# Results 
.center[
```{r echo=FALSE}
#| out.width: "40%"
knitr::include_graphics(here("figs", "s1a.png"))
```
]

---
# Results 
.pull-left[
```{r echo=FALSE}
#| out.width: "70%"
knitr::include_graphics(here("figs", "s1e.png"))
```
]
--
.pull-right[
```{r echo=FALSE}
#| out.width: "75%"
knitr::include_graphics(here("figs", "s1i.png"))
```
]

---
# Results 
.pull-left[
```{r echo=FALSE}
#| out.width: "70%"
knitr::include_graphics(here("figs", "s1o.png"))
```
]
--
.pull-right[
```{r echo=FALSE}
#| out.width: "73%"
knitr::include_graphics(here("figs", "s1u.png"))
```
]

---
```{r echo=FALSE}
#| out.width: "100%"
knitr::include_graphics(here("figs", "s1_prob.png"))
```

.center[
```{r echo=FALSE}
#| out.width: "40%"
knitr::include_graphics(here("figs", "vowel_mismatch_decision.jpg"))

```
]

---
# Results: LexTALE

.center[
```{r echo=FALSE}
#| out.width: "95%"
knitr::include_graphics(here("figs", "s1audio.png"))

```
]
---
# Results: LexTALE
.center[
```{r echo=FALSE}
#| out.width: "110%"
knitr::include_graphics(here("figs", "s1av.png"))

```
]

---
# Results: LexTALE
.center[
```{r echo=FALSE}
#| out.width: "100%"
knitr::include_graphics(here("figs", "s1visual.png"))

```
]
---
# Results: LexTALE
.center[
```{r echo=FALSE}
#| out.width: "90%"
knitr::include_graphics(here("figs", "s1avmis.png"))

```
]
---
.center[
```{r echo=FALSE}
#| out.width: "55%"
knitr::include_graphics(here("figs", "s1_all.png"))

```
]

---

# Discussion.

- **Focus: Role of visual cues (lip and facial movements)**

- Strong correlation found between linguistic proficiency and the benefits derived from visual cues. (Peelle & Sommers, 2015; Tye-Murray et al., 2007)
  - Both visual and auditory cues enrich L2 speech perception, aiding better understanding and communication

---
# The visual effect 
      - Visual cues lead to enhanced accuracy and reduced vowel misidentification.
      - Higher proficiency learners show enhanced adaptability to visual cues. 
      - Mismatch Condition Insight:
       Exposure to auditory /a/ with visual /i/ made a subset of participants choose vowel /o/.
       Data point: β = 1.12 HDI =[0.31, 1.94] ROPE = 0, MPE = 1. 
      

# The results support the PAM-L2 and SLM models.

  - Difficulty noticed in distinguishing vowel pairs: /e-i/ and /u-o/.
      -- Possible influence of /u/ fronting in North American English.
      Importance of visual neighbors.
    
     - Increased proficiency: Distinct phonetic categories for Spanish vowels.
     - High profiency learners were the ones who better could use visual cues only. 



---
# Conclusion

- L2 speakers beneficent from bimodal perception. 

- Learners develop new categories (phonemes and visemes) as proficiency advances. 

- The scope of this study can be extrapolated to the importance of integrating visual cues in language instruction to improve phonetic discrimination, particularly for learners with developing linguistic abilities.
  - Specifically in online language courses

---
# Questions?


---
# References


Best, C. T., Tyler, M., Bohn, O., & Munro, M. (2007). Nonnative and second-language speech
perception. Language Experience in Second Language Speech Learning, 13–34.


Bradlow, A. R., & Bent, T. (2002). The clear speech effect for non-native listeners. The Journal of the Acoustical Society of America, 112(1), 272–284.


Devlin, J. T., & Aydelott, J. (2009). Speech perception: Motoric contributions versus the motor theory. Current Biology, 19(5), R198–R200.


Elvin, J., Escudero, P., & Vasiliev, P. (2014). Spanish is better than english for discriminating portuguese vowels: Acoustic similarity versus vowel inventory size. Frontiers in Psychology, 5, 1188.


Escudero, P., & Williams, D. (2012). Native dialect influences second-language vowel perception: Peruvian versus iberian spanish learners of dutch. The Journal of the Acoustical Society of America, 131(5), EL406–EL412.


Fenwick, S. E., Best, C. T., Davis, C., & Tyler, M. D. (2017). The influence of auditory-visual speech and clear speech on cross-language perceptual assimilation. Speech Communication, 92, 114–124.

---
# References

Fisher, C. G. (1968). Confusions among visually perceived consonants. Journal of Speech and Hearing Research, 11(4), 796–804.


Flege, J. E., & Bohn, O.-S. (2021). The revised speech learning model (SLM-r). Second Language Speech Learning: Theoretical and Empirical Progress, 10(9781108886901.002).


Fowler, C. A. (1986). An event approach to the study of speech perception from a direct–realist perspective. Journal of Phonetics, 14(1), 3–28.

Gordon, L. S. (2008). Factors affecting english speakers’ perception of L2 spanish vowels. Georgetown University.


Hazan, V., Sennema, A., Faulkner, A., Ortega-Llebaria, M., Iba, M., & Chung, H. (2006). The use of visual cues in the perception of non-native consonant contrasts. The Journal of the Acoustical Society of America, 119(3), 1740–1751.
---
# References

Hualde, J. I. (2005). The sounds of spanish with audio CD. Cambridge University Press.


Hualde, J. I. (2013). Los sonidos del español: Spanish language edition. Cambridge University Press.


Inceoglu, S. (2022). Language experience and subjective word familiarity on the multimodal perception of non-native vowels. Language and Speech, 65(1), 173–192.


Lahoz-Bengoechea, J. M., & Jiménez-Bravo, M. (2021). Spoken word boundary detection in ambiguous resyllabification contexts in spanish.


Lemhöfer, K., & Broersma, M. (2012). Introducing LexTALE: A quick and valid lexical test for advanced learners of english. Behavior Research Methods, 44, 325–343.


Leonte, A., Colzato, L. S., Steenbergen, L., Hommel, B., & Akyürek, E. G. (2018). Supplementation of gamma-aminobutyric acid (GABA) affects temporal, but not spatial visual attention. Brain and Cognition, 120, 8–16.


Levy, E. S., & Strange, W. (2008). Perception of french vowels by american english adults with and without french language experience. Journal of Phonetics, 36(1), 141–157.
---
# References




