<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>From Eyes to Ears: The Visual and Auditory Dynamics of Spanish Vowels for English Students</title>
    <meta charset="utf-8" />
    <meta name="author" content="" />
    <meta name="date" content="2023-10-03" />
    <script src="libs/header-attrs-2.20/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/rutgers-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/rutgers.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# From Eyes to Ears: The Visual and Auditory Dynamics of Spanish Vowels for English Students
]
.author[
### 
]
.institute[
### Rutgers University
]
.date[
### 2023-10-03
]

---




# How do we perceive language?

.pull-left[
&lt;img src="figs/eye1.jpg" width="100%" /&gt;
]


.pull-right[
- Understanding involves bringing information from various sources, including the sound of speech, our knowledge of language structure, and context. 

- Visual Cues as Facilitating Agents (O’Neill, 1954; Ross et al., 2007; Sumby &amp; Pollack, 1954).

- Current research trends: SLA bimodal speech perception indicates beneficial implications for second language acquisition (E.g., Hazan et al., 2006; Inceoglu, 2022).]

---
# Background: Speech perception. 

--

## Motor theory (Liberman &amp; Mattingly, 1985) 
- Recognizing underlying motor commands: “tongue backing,” “lip rounding,” “jaw raising”
- McGurk effect: Fused language perception (McGurk &amp; MacDonald, 1976) 

--

## The Direct Realist Theory (Fowler, 1986).
- Perception based on articulatory events.
- Can rely on multiple information sources

#### Effect of visual cues? How do humans perceive sound in noisy environments? 

---

# Background: Second language speech perception

--

## The Speech Learning Model (revised) (Flege &amp; Bohn, 2021). 

- Evolving phonetic categories in second-language learning. 
- Considers the role of multiple information sources. 

--

## The Perception Assimilation Model (PAM-L2) (Best et al, 2007). 

- L2 sounds are assimilated to similar L1 sounds.
- Predictions made from phonemic inventories.
- More vowel phonemes does not equate to better perception. Escudero &amp; Williams (2012), Gordon (2008),Inceoglu (2022). 
  
---
# Background: Second language speech and visual perception. 

## Within the PAM-L2 precepts

- Hazan et al. (2006) identified three types of visemes 
  - (1) Present in both L1 and L2 
  - (2) Unique to L2
  - (3) Different in L1 and L2 
  
A viseme was defined as: 

*Visual representation of speech through mouth &amp; lip movements. *

- **L1 phonemes and visemes affect L2 perception**
  - L1 phonemes &amp; visemes influence L2 perception. Hindered acquisition for Categories (2) &amp; (3).
---

# Background: Second language speech and visual perception.  

- Fenwick et al. (2017) similar phonemes &amp; visemes in L1 are easier to categorize. 

- Desroches et al. (2022) Bilinguals have flexible language systems. 
  - **Cross-language connections** between lexical representations and phonology.
  - Capability for top-down cross-language connections. 

- Marian et al. (2018), Bilinguals experience the McGurk effect more than monolinguals 
  - Dual visemic &amp; phonemic inventories broaden linguistic range.
  
---

# Research Questions  

1.	Are second-language English learners of Spanish capable of identifying vowels by visually observing the respective articulation in natural speech? Does an association exist between their accuracy and language proficiency?

2.	How does the disparity between auditory and visual inputs hinder the processing of auditory information? Does a learner’s proficiency level affect their capacity to efficiently process and prioritize between two conflicting input channels?

---

# The study: Identification of Spanish vowels

.pull-left[
- **Recording** in a sound attenuated booth. 
- **Video Framing** trimmed from septal cartilage to mandible mentalis muscle.
- Target words. 
- Consonants /p, t, k, b, d, g, f, j, s and θ/. 
- With /a, e, i, o u/.
  - Created bi-syllable words.
- All possible answers were provided 
  - Audio only     50 items
  - Visual only    50 items
  - Audiovisual    50 items
  - Mismatch       50 items
- **Total**     200 items 
]
--
.pull-right[
&lt;img src="figs/vowel_mismatch_decision.jpg" width="100%" /&gt;
##### Procedure to create vowel mismatch condition
]
---
.pull-left[
## Procedure 
  
1. LexTALE test
2. The study
 Input was randomized 
3. Background Questionnaire

## Participants 
&lt;img src="figs/s1part.png" width="80%" /&gt;
]
--
.pull-right[
## Statistical analysis

- Employed Bayesian multinomial logistic regression.
- Analyzed probability of identifying one of five Spanish vowels.
- Responses modeled on condition and proficiency for: 
  - audio, 
  - visual-only 
  - audiovisual
  - audiovisual mismatch
  ]

---
# Results 
.center[
&lt;img src="figs/s1a.png" width="40%" /&gt;
]

---
# Results 
.pull-left[
&lt;img src="figs/s1e.png" width="70%" /&gt;
]
--
.pull-right[
&lt;img src="figs/s1i.png" width="75%" /&gt;
]

---
# Results 
.pull-left[
&lt;img src="figs/s1o.png" width="70%" /&gt;
]
--
.pull-right[
&lt;img src="figs/s1u.png" width="73%" /&gt;
]

---
&lt;img src="figs/s1_prob.png" width="100%" /&gt;

.center[
&lt;img src="figs/vowel_mismatch_decision.jpg" width="40%" /&gt;
]

---
# Results: LexTALE

.center[
&lt;img src="figs/s1audio.png" width="95%" /&gt;
]
---
# Results: LexTALE
.center[
&lt;img src="figs/s1av.png" width="110%" /&gt;
]

---
# Results: LexTALE
.center[
&lt;img src="figs/s1visual.png" width="100%" /&gt;
]
---
# Results: LexTALE
.center[
&lt;img src="figs/s1avmis.png" width="90%" /&gt;
]
---
.center[
&lt;img src="figs/s1_all.png" width="55%" /&gt;
]

---

# Discussion.

- **Focus: Role of visual cues (lip and facial movements)**

- Strong correlation found between linguistic proficiency and the benefits derived from visual cues. (Peelle &amp; Sommers, 2015; Tye-Murray et al., 2007)
  - Both visual and auditory cues enrich L2 speech perception, aiding better understanding and communication

---
# The visual effect 
      - Visual cues lead to enhanced accuracy and reduced vowel misidentification.
      - Higher proficiency learners show enhanced adaptability to visual cues. 
      - Mismatch Condition Insight:
       Exposure to auditory /a/ with visual /i/ made a subset of participants choose vowel /o/.
       Data point: β = 1.12 HDI =[0.31, 1.94] ROPE = 0, MPE = 1. 
      

# The results support the PAM-L2 and SLM models.

  - Difficulty noticed in distinguishing vowel pairs: /e-i/ and /u-o/.
      -- Possible influence of /u/ fronting in North American English.
      Importance of visual neighbors.
    
     - Increased proficiency: Distinct phonetic categories for Spanish vowels.
     - High profiency learners were the ones who better could use visual cues only. 



---
# Conclusion

- L2 speakers beneficent from bimodal perception. 

- Learners develop new categories (phonemes and visemes) as proficiency advances. 

- The scope of this study can be extrapolated to the importance of integrating visual cues in language instruction to improve phonetic discrimination, particularly for learners with developing linguistic abilities.
  - Specifically in online language courses

---
# Questions?


---
# References


Best, C. T., Tyler, M., Bohn, O., &amp; Munro, M. (2007). Nonnative and second-language speech
perception. Language Experience in Second Language Speech Learning, 13–34.


Bradlow, A. R., &amp; Bent, T. (2002). The clear speech effect for non-native listeners. The Journal of the Acoustical Society of America, 112(1), 272–284.


Devlin, J. T., &amp; Aydelott, J. (2009). Speech perception: Motoric contributions versus the motor theory. Current Biology, 19(5), R198–R200.


Elvin, J., Escudero, P., &amp; Vasiliev, P. (2014). Spanish is better than english for discriminating portuguese vowels: Acoustic similarity versus vowel inventory size. Frontiers in Psychology, 5, 1188.


Escudero, P., &amp; Williams, D. (2012). Native dialect influences second-language vowel perception: Peruvian versus iberian spanish learners of dutch. The Journal of the Acoustical Society of America, 131(5), EL406–EL412.


Fenwick, S. E., Best, C. T., Davis, C., &amp; Tyler, M. D. (2017). The influence of auditory-visual speech and clear speech on cross-language perceptual assimilation. Speech Communication, 92, 114–124.

---
# References

Fisher, C. G. (1968). Confusions among visually perceived consonants. Journal of Speech and Hearing Research, 11(4), 796–804.


Flege, J. E., &amp; Bohn, O.-S. (2021). The revised speech learning model (SLM-r). Second Language Speech Learning: Theoretical and Empirical Progress, 10(9781108886901.002).


Fowler, C. A. (1986). An event approach to the study of speech perception from a direct–realist perspective. Journal of Phonetics, 14(1), 3–28.

Gordon, L. S. (2008). Factors affecting english speakers’ perception of L2 spanish vowels. Georgetown University.


Hazan, V., Sennema, A., Faulkner, A., Ortega-Llebaria, M., Iba, M., &amp; Chung, H. (2006). The use of visual cues in the perception of non-native consonant contrasts. The Journal of the Acoustical Society of America, 119(3), 1740–1751.
---
# References

Hualde, J. I. (2005). The sounds of spanish with audio CD. Cambridge University Press.


Hualde, J. I. (2013). Los sonidos del español: Spanish language edition. Cambridge University Press.


Inceoglu, S. (2022). Language experience and subjective word familiarity on the multimodal perception of non-native vowels. Language and Speech, 65(1), 173–192.


Lahoz-Bengoechea, J. M., &amp; Jiménez-Bravo, M. (2021). Spoken word boundary detection in ambiguous resyllabification contexts in spanish.


Lemhöfer, K., &amp; Broersma, M. (2012). Introducing LexTALE: A quick and valid lexical test for advanced learners of english. Behavior Research Methods, 44, 325–343.


Leonte, A., Colzato, L. S., Steenbergen, L., Hommel, B., &amp; Akyürek, E. G. (2018). Supplementation of gamma-aminobutyric acid (GABA) affects temporal, but not spatial visual attention. Brain and Cognition, 120, 8–16.


Levy, E. S., &amp; Strange, W. (2008). Perception of french vowels by american english adults with and without french language experience. Journal of Phonetics, 36(1), 141–157.
---
# References




    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
